{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamScraper:\n",
    "    def __init__(self, url):\n",
    "        if(url):\n",
    "            self.response = requests.get(url)\n",
    "            self.team_soup = BeautifulSoup(self.response.text, parser='lxml')\n",
    "\n",
    "            self.stat_table = StatTableHandler(self.team_soup)\n",
    "            self.team_info = TeamInfoHandler(self.team_soup)\n",
    "        else:\n",
    "            print(\"URL is None\")\n",
    "    def parse_team_table(self):\n",
    "        print(\"bleh\")\n",
    "        \n",
    "        \n",
    "           \n",
    "        \n",
    "        #iterate through rows and get \n",
    "        \n",
    "    def get_stat_csv(self):\n",
    "        # Update to include team info in csv title\n",
    "        self.stat_table.table_df.to_csv(self.team_info.get_name() + '.csv', index=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def print_url(self):\n",
    "        print(self.url)\n",
    "        \n",
    "        \n",
    "class StatTableHandler:\n",
    "    def __init__(self, team_soup):\n",
    "        table = team_soup.find('div', {'class':'table-responsive'})\n",
    "        self.table = table\n",
    "        self.table_headers = self.get_table_headers()\n",
    "        self.table_contents = self.get_table_contents()\n",
    "        self.table_df = self.generate_dataframe()\n",
    "    def get_table_headers(self):\n",
    "        # Get table header for csv headers\n",
    "        table_headers = self.table.find_all('th')        \n",
    "        final_headers = []\n",
    "        for table_header in table_headers:            \n",
    "            # If the tag has attributes (ie a full name), get them\n",
    "            header_attrs = table_header.attrs\n",
    "            if(header_attrs):\n",
    "                final_headers.append(table_header['title'])\n",
    "            else:\n",
    "                final_headers.append(table_header.contents[0])\n",
    "        return final_headers\n",
    "    def get_table_contents(self):\n",
    "        table_body = self.table.find('tbody')\n",
    "        rows = table_body.find_all('tr')\n",
    "        final_rows = []\n",
    "        # Iterate through and process table rows\n",
    "        for row in rows:\n",
    "            # iterate through each row's columns\n",
    "            scraped_row = [td.text for td in row.find_all('td')]\n",
    "            final_rows.append(scraped_row)\n",
    "        return final_rows\n",
    "    \n",
    "    def generate_dataframe(self):\n",
    "        table_df = pd.DataFrame(self.table_contents, columns = self.table_headers)\n",
    "        return table_df\n",
    "    \n",
    "class TeamInfoHandler:\n",
    "    def __init__(self, team_soup):\n",
    "        name_record = team_soup.find('h1', {'class':'m-b-0'}).text.split('(')\n",
    "        self.name = name_record[0].strip()\n",
    "        self.record = name_record[1][:-1].strip()\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    def get_record(self):\n",
    "        return self.record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to handle a division\n",
    "class DivisionScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        resp = requests.get(self.url)\n",
    "        division_soup = BeautifulSoup(resp.text, parser='lxml')\n",
    "        table = division_soup.find('div', {'class':'box clearfix'})\n",
    "        division_and_conference = table.find_all('table', {'class':'table table-striped box'})\n",
    "        self.division_table = division_and_conference[0]\n",
    "        self.conference_tables = division_and_conference[1:]\n",
    "        self.division_links = self.get_division_links()\n",
    "        \n",
    "    def get_division_links(self, master_url = 'https://www.insidelacrosse.com/'):\n",
    "        body = self.division_table.find('tbody')\n",
    "        teams = body.find_all('tr')\n",
    "        division_links = []\n",
    "        for row in teams:\n",
    "            #Link is the first element in the row\n",
    "            link = row.find_all('td')[0].find('a')['href']\n",
    "            # add stats to url\n",
    "            split_link = link.split('/')\n",
    "            split_link[0] = split_link[1]\n",
    "            split_link[1] = 'stats'\n",
    "            \n",
    "            # Rejion\n",
    "            final_link = '/'.join(split_link)\n",
    "            division_links.append(master_url + final_link)\n",
    "        return division_links\n",
    "            \n",
    "    \n",
    "    def get_url(self):\n",
    "        return self.url\n",
    "    \n",
    "    def get_division_table(self):\n",
    "        return self.division_table\n",
    "    \n",
    "    # ToDo - complete this method\n",
    "    def get_conference_tables(self):\n",
    "        return self.conference_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bdf5ba61db3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md1_links\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTeamScraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stat_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-412cfd8e8404>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStatTableHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteam_soup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteam_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTeamInfoHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteam_soup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"URL is None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-412cfd8e8404>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, team_soup)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mname_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteam_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'm-b-0'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'('\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_record\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_record\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "div_url = 'https://www.insidelacrosse.com/league/di/teams/2021'\n",
    "div_scraper = DivisionScraper(div_url)\n",
    "\n",
    "d1_links = div_scraper.division_links\n",
    "\n",
    "for link in d1_links:\n",
    "    ts = TeamScraper(link)\n",
    "    ts.get_stat_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
